# Setup Instructions

1. Run `pod install`.
1. Download the `gemma-2b-it-cpu-int4.bin` and `gemma-2b-it-gpu-int4.bin` model from [the documentation](https://developers.google.com/mediapipe/solutions/genai/llm_inference#models) into this directory.
1. Open `InferenceExample.xcworkspace` and run the project.
