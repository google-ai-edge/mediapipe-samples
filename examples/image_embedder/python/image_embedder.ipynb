{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Image Embedding with MediaPipe Tasks\n",
        "\n",
        "This notebook will show you how to use the MediaPipe Tasks Python API to compare two separate image files to determine how similar they are. These values will range from -1 to 1 with 1 being the same image This is done through a technique called cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "You can start by installing the necessary dependencies for your project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "The next step you will take is to download the off-the-shelf model that will be used for image embedding. In this case you will use mobilenet, but you may use any other appropriate model or a model that you have built for your own specific use-cases with MediaPipe Tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -O embedder.tflite -q https://storage.googleapis.com/mediapipe-models/image_embedder/mobilenet_v3_small/float32/1/mobilenet_v3_small.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "For the final preparation step, you will need to have two separate images that can be compared. You can download two provided images through the following code, or you can download your own from a different location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "\n",
        "IMAGE_FILENAMES = ['burger.jpg', 'burger_crop.jpg']\n",
        "\n",
        "for name in IMAGE_FILENAMES:\n",
        "  url = f'https://storage.googleapis.com/mediapipe-assets/{name}'\n",
        "  urllib.request.urlretrieve(url, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XRmapjySMN"
      },
      "source": [
        "# Performing Image Embedding\n",
        "Now that you have retrieved the two images that will be compared, you can display them to confirm that they look correct. For this example you should see two separate, but similar, pictures of burgers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rjHk72-lmHX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "\n",
        "DESIRED_HEIGHT = 480\n",
        "DESIRED_WIDTH = 480\n",
        "\n",
        "def resize_and_show(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
        "  cv2_imshow(img)\n",
        "\n",
        "\n",
        "# Preview the images.\n",
        "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
        "for name, image in images.items():\n",
        "  print(name)\n",
        "  resize_and_show(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "Once everything looks good, you can start performing inference. You will start by creating the options that are necessary for associating your model with the Image Embedder, as well as some customizations.\n",
        "\n",
        "Next you will create the Image Embedder, then format your two images for MediaPipe so that you can use cosine similarity to compare them.\n",
        "\n",
        "Finally, you will display the similarity value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# Create options for Image Embedder\n",
        "base_options = python.BaseOptions(model_asset_path='embedder.tflite')\n",
        "l2_normalize = True #@param {type:\"boolean\"}\n",
        "quantize = True #@param {type:\"boolean\"}\n",
        "options = vision.ImageEmbedderOptions(\n",
        "    base_options=base_options, l2_normalize=l2_normalize, quantize=quantize)\n",
        "\n",
        "\n",
        "# Create Image Embedder\n",
        "with vision.ImageEmbedder.create_from_options(options) as embedder:\n",
        "\n",
        "  # Format images for MediaPipe\n",
        "  first_image = mp.Image.create_from_file(IMAGE_FILENAMES[0])\n",
        "  second_image = mp.Image.create_from_file(IMAGE_FILENAMES[1])\n",
        "  first_embedding_result = embedder.embed(first_image)\n",
        "  second_embedding_result = embedder.embed(second_image)\n",
        "\n",
        "  # Calculate and print similarity\n",
        "  similarity = vision.ImageEmbedder.cosine_similarity(\n",
        "      first_embedding_result.embeddings[0],\n",
        "      second_embedding_result.embeddings[0])\n",
        "  print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0zj8q2CcLaR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
