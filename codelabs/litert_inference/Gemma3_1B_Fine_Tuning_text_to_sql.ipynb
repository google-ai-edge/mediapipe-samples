{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-ai-edge/mediapipe-samples/blob/main/codelabs/litert_inference/Gemma3_1B_Fine_Tuning_text_to_sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma-3-1B fine-tuning with SFT and on-device deployment with AI Edge Torch and MediaPipe.\n",
        "This guide walks you through how to fine-tune a Gemma3-1B model using a synthetic dataset and LoRA adaptors followed by conversion to the LiteRT format for mobile deployment. Lastly, we will load the LiteRT model and perform some inference in the colab environment.\n",
        "\n",
        "Note: to run this colab smoothly you will need a Colab Pro subscription which gives you access to faster GPU instances with more RAM. We recommend using an A100 instance.\n",
        "\n",
        "# What is Low-Rank Adaptation (LoRA)\n",
        "This guide demonstrates the use of [Low-Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685), which emerged as a popular method to efficiently fine-tune LLMs as it reduces computational resource requirements while maintaining high performance. With LoRA, the pretrained model weights are frozen. Then trainable adapter layers (LoRA) are attached and only the adapter layers are trained. Afterwards, the adapter weights can be merged with the base model or kept as a separate adapter.\n",
        "\n",
        "# Prerequisites\n",
        "* Before you can start training, you have to make sure that you accepted the terms of use for Gemma. You can accept the license on [Hugging Face](http://huggingface.co/google/gemma-3-1b-pt) by clicking on the Agree and access repository button on the model page at: http://huggingface.co/google/gemma-3-1b-pt.\n",
        "* Create a HuggingFace Finegrained access token with the following permissions (you will push your model to the Hub during training):\n",
        "![hf_access_token.png](data:image/png;base64,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)\n",
        "\n",
        "* Open Colab Secrets: In your Google Colab notebook, locate the Secrets (key) icon in the left-hand sidebar and click on it.\n",
        "\n",
        "* Add a new secret: Click the `Add Secret` button.\n",
        "\n",
        "* Name your secret: Enter `HF_TOKEN` for your token in the `Name` field.\n",
        "\n",
        "* Paste your token: In the `Value` field, paste the actual token you want to store.\n",
        "\n",
        "Note: When running notebooks in this repository with Google Colab, some users may see the following warning message:\n",
        "\n",
        "![colab_warning.jpeg](data:image/jpeg;base64,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)\n",
        "\n",
        "Please click `Restart Session` and run the next cell (do not run the pip install cell a second time)."
      ],
      "metadata": {
        "id": "x8yA06Zb-Tjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbLjvqxXK74K"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install --upgrade \"torch==2.6.0\" \\\n",
        "  \"transformers>=4.51.3\" \\\n",
        "  \"datasets==3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"trl==0.15.2\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  \"flash-attn==2.7.4.post1\" \\\n",
        "  ai-edge-torch-nightly==0.6.0.dev20250523 \\\n",
        "  ai-edge-litert==1.3.0 \\\n",
        "  mediapipe==0.10.21"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login into Hugging Face Hub\n",
        "hf_token = userdata.get('HF_TOKEN') # If you are running inside a Google Colab\n",
        "login(hf_token)\n",
        "\n",
        "# For the purposes of this demonstration we disable W&B integration.\n",
        "# See https://huggingface.co/docs/transformers/main_classes/callback#transformers.integrations.WandbCallback for details.\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "U8b0AFNELllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and prepare the fine-tuning dataset\n",
        "When fine-tuning LLMs, it is important to know your use case and the task you want to solve. This helps you create a dataset to fine-tune your model. If you haven't defined your use case yet, you might want to go back to the drawing board.\n",
        "\n",
        "As an example, this guide focuses on the following use case:\n",
        "* Fine-tune a natural language to SQL model for seamless integration into a data analysis tool. The objective is to significantly reduce the time and expertise required for SQL query generation, enabling even non-technical users to extract meaningful insights from data.\n",
        "\n",
        "Text-to-SQL can be a good use case for fine-tuning LLMs, as it is a complex task that requires a lot of (internal) knowledge about the data and the SQL language.\n",
        "\n",
        "Once you have determined that fine-tuning is the right solution, you need a dataset to fine-tune. The dataset should be a diverse set of demonstrations of the task(s) you want to solve. There are several ways to create such a dataset, including:\n",
        "\n",
        "* Using existing open-source datasets, such as [Spider](https://huggingface.co/datasets/spider).\n",
        "* Using synthetic datasets created by LLMs, such as [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca).\n",
        "* Using datasets created by humans, such as [Dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k).\n",
        "* Using a combination of the methods, such as [Orca](https://huggingface.co/datasets/Open-Orca/OpenOrca).\n",
        "\n",
        "Each of the methods has its own advantages and disadvantages and depends on the budget, time, and quality requirements. For example, using an existing dataset is the easiest but might not be tailored to your specific use case, while using domain experts might be the most accurate but can be time-consuming and expensive. It is also possible to combine several methods to create an instruction dataset, as shown in [Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707).\n",
        "\n",
        "This guide uses an already existing dataset ([philschmid/gretel-synthetic-text-to-sql](https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql)), a high quality synthetic Text-to-SQL dataset including natural language instructions, schema definitions, reasoning and the corresponding SQL query.\n",
        "\n",
        "[Hugging Face TRL](https://huggingface.co/docs/trl/en/index) supports automatic templating of conversation dataset formats. This means you only need to convert your dataset into the right json objects, and trl takes care of templating and putting it into the right format.\n",
        "\n",
        "```json\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
        "```\n",
        "\n",
        "The [philschmid/gretel-synthetic-text-to-sql](https://huggingface.co/datasets/philschmid/gretel-synthetic-text-to-sql) contains over 100k samples. To keep the guide small, it is downsampled to only use 10,000 samples.\n",
        "\n",
        "You can now use the Hugging Face Datasets library to load the dataset and create a prompt template to combine the natural language instruction, schema definition and add a system message for your assistant."
      ],
      "metadata": {
        "id": "UTLiYWlIEaMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# System message for the assistant\n",
        "system_message = \"\"\"You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\"\"\"\n",
        "\n",
        "# User prompt that combines the user query and the schema\n",
        "user_prompt = \"\"\"Given the <USER_QUERY> and the <SCHEMA>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
        "\n",
        "<SCHEMA>\n",
        "{context}\n",
        "</SCHEMA>\n",
        "\n",
        "<USER_QUERY>\n",
        "{question}\n",
        "</USER_QUERY>\n",
        "\"\"\"\n",
        "def create_conversation(sample):\n",
        "  return {\n",
        "    \"messages\": [\n",
        "      # {\"role\": \"system\", \"content\": system_message},\n",
        "      {\"role\": \"user\", \"content\": user_prompt.format(question=sample[\"sql_prompt\"], context=sample[\"sql_context\"])},\n",
        "      {\"role\": \"assistant\", \"content\": sample[\"sql\"]}\n",
        "    ]\n",
        "  }\n",
        "\n",
        "# Load dataset from the hub\n",
        "dataset = load_dataset(\"philschmid/gretel-synthetic-text-to-sql\", split=\"train\")\n",
        "dataset = dataset.shuffle().select(range(12500))\n",
        "\n",
        "# Convert dataset to OAI messages\n",
        "dataset = dataset.map(create_conversation, remove_columns=dataset.features,batched=False)\n",
        "# split dataset into 10,000 training samples and 2,500 test samples\n",
        "dataset = dataset.train_test_split(test_size=2500/12500)\n",
        "\n",
        "# Print formatted user prompt\n",
        "print(dataset[\"train\"][345][\"messages\"][1][\"content\"])"
      ],
      "metadata": {
        "id": "C1qFUIDwL2KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Gemma using TRL and the SFTTrainer\n",
        "You are now ready to fine-tune your model. Hugging Face TRL [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer) (Supervised Fine-Tuning Trainer) makes it straightforward to supervise fine-tune open LLMs. The SFTTrainer is a subclass of the Trainer from the transformers library and supports all the same features, including logging, evaluation, and checkpointing, but adds additional quality of life features, including:\n",
        "\n",
        "* Dataset formatting, including conversational and instruction formats\n",
        "* Training on completions only, ignoring prompts\n",
        "* Packing datasets for more efficient training\n",
        "* Parameter-efficient fine-tuning (PEFT) support including LoRA\n",
        "* Preparing the model and tokenizer for conversational fine-tuning (such as adding special tokens)\n",
        "\n",
        "The following code loads the Gemma model and tokenizer from Hugging Face."
      ],
      "metadata": {
        "id": "5a5McK20F1jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForImageTextToText\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"google/gemma-3-1b-pt\" # or `google/gemma-3-4b-pt`, `google/gemma-3-12b-pt`, `google/gemma-3-27b-pt`\n",
        "\n",
        "# Select model class based on id\n",
        "if model_id == \"google/gemma-3-1b-pt\":\n",
        "    model_class = AutoModelForCausalLM\n",
        "else:\n",
        "    model_class = AutoModelForImageTextToText\n",
        "\n",
        "# Check if GPU benefits from bfloat16\n",
        "if torch.cuda.get_device_capability()[0] >= 8:\n",
        "    torch_dtype = torch.bfloat16\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "\n",
        "# Define model init arguments\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"eager\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
        "    torch_dtype=torch_dtype, # What torch dtype to use, defaults to auto\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = model_class.from_pretrained(model_id, **model_kwargs, token=hf_token)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\", token=hf_token) # Load the Instruction Tokenizer to use the official Gemma template"
      ],
      "metadata": {
        "id": "uVgz2fffL265"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `SFTTrainer` supports a native integration with `peft`, which makes it straightforward to efficiently tune LLMs using LoRA. You only need to create a `LoraConfig` and provide it to the trainer."
      ],
      "metadata": {
        "id": "g7B7yv-7IA69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    modules_to_save=[\"lm_head\", \"embed_tokens\"] # make sure to save the lm_head and embed_tokens as you train the special tokens\n",
        ")"
      ],
      "metadata": {
        "id": "nBPb0IOmMyjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you can start your training, you need to define the hyperparameter you want to use in a `SFTConfig` instance."
      ],
      "metadata": {
        "id": "b_T92mV_ItBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "args = SFTConfig(\n",
        "    output_dir=\"gemma-text-to-sql\",         # directory to save and repository id\n",
        "    max_seq_length=512,                     # max sequence length for model and packing of the dataset\n",
        "    packing=True,                           # Groups multiple samples in the dataset into a single sequence\n",
        "    # For real use-cases, you will want to train your model with epochs rather than a small number of steps\n",
        "    num_train_epochs=3,                     # number of training epochs\n",
        "    #max_steps=100,                          # mutually exclusive with num_train_epochs\n",
        "    per_device_train_batch_size=1,          # batch size per device during training\n",
        "    gradient_accumulation_steps=4,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                     # learning rate, based on HF blog post\n",
        "    fp16=True if torch_dtype == torch.float16 else False,   # use float16 precision\n",
        "    bf16=True if torch_dtype == torch.bfloat16 else False,   # use bfloat16 precision\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on HF blog post\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on HF blog post\n",
        "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False, # We template with special tokens\n",
        "        \"append_concat_token\": True, # Add EOS token as separator token between examples\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "7h_-rFGvM3FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now have every building block you need to create your `SFTTrainer` to start the training of your model."
      ],
      "metadata": {
        "id": "OtSt9b1XIv_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "# Create Trainer object\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "xr1ievngM6GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training by calling the `train()` method."
      ],
      "metadata": {
        "id": "9Yb1W_ymJB--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training, the model will be automatically saved to the Hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model again to the Hugging Face Hub\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "iRMI6aAyNFnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you can test your model, make sure to free the memory."
      ],
      "metadata": {
        "id": "O5AgtNYLJExv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "UbamrfNiUciJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using LoRA, you only train adapters and not the full model. This means when saving the model during training you only save the adapter weights and not the full model. If you want to save the full model, which makes it easier to use with serving stacks like vLLM or TGI, you can merge the adapter weights into the model weights using the `merge_and_unload` method and then save the model with the `save_pretrained` method. This saves a default model, which can be used for inference."
      ],
      "metadata": {
        "id": "kDunF05YJLtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# Load Model base model\n",
        "model = model_class.from_pretrained(model_id, low_cpu_mem_usage=True)\n",
        "\n",
        "# Merge LoRA and base model and save\n",
        "peft_model = PeftModel.from_pretrained(model, args.output_dir)\n",
        "merged_model = peft_model.merge_and_unload()\n",
        "merged_model.save_pretrained(\"merged_model\", safe_serialization=True, max_shard_size=\"2GB\")\n",
        "\n",
        "processor = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "processor.save_pretrained(\"merged_model\")"
      ],
      "metadata": {
        "id": "r5n1TSskUgvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model Inference and generate SQL queries\n",
        "After the training is done, you'll want to evaluate and test your model. You can load different samples from the test dataset and evaluate the model on those samples."
      ],
      "metadata": {
        "id": "f7pQP_gBJm88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"gemma-text-to-sql\"\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = model_class.from_pretrained(\n",
        "  model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch_dtype,\n",
        "  attn_implementation=\"eager\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "IFB2W_VMvROH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load a random sample from the test dataset and generate a SQL command."
      ],
      "metadata": {
        "id": "Bt6agv5vJpq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "# Load the model and tokenizer into the pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Load a random sample from the test dataset\n",
        "random.seed(1337)\n",
        "rand_idx = random.randint(0, len(dataset[\"test\"]))\n",
        "test_sample = dataset[\"test\"][rand_idx]\n",
        "\n",
        "# Convert as test example into a prompt with the Gemma template\n",
        "stop_token_ids = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "prompt = pipe.tokenizer.apply_chat_template(test_sample[\"messages\"][:1], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# Generate our SQL query.\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=False, temperature=0.1, top_k=50, top_p=0.1, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "\n",
        "# Extract the user query and original answer\n",
        "print(\"======================================================================\")\n",
        "print(\"Prompt:\")\n",
        "print(f\"  Context:\\n   \", re.search(r'<SCHEMA>\\n(.*?)\\n</SCHEMA>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip())\n",
        "print(f\"  Query:\\n   \", re.search(r'<USER_QUERY>\\n(.*?)\\n</USER_QUERY>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip())\n",
        "print(\"======================================================================\")\n",
        "print(f\"Original Answer:\\n  {test_sample['messages'][1]['content']}\")\n",
        "print(\"======================================================================\")\n",
        "print(f\"Generated Answer:\\n  {outputs[0]['generated_text'][len(prompt):]}\")"
      ],
      "metadata": {
        "id": "mh1Pu07Vvlmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load up the checkpoint in AI Edge Torch and convert to LiteRT.\n",
        "Now let's convert our model (including 8-bit quantization) to LiteRT format, this will take roughly 10+ minutes to finish. The output tflite will be saved in the `/content` subfolder, with the name `gemma3_1b_finetune_q8_ekv1024.tflite`."
      ],
      "metadata": {
        "id": "yw2tX4sfJwYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from ai_edge_torch.generative.examples.gemma3 import gemma3\n",
        "from ai_edge_torch.generative.layers import kv_cache\n",
        "from ai_edge_torch.generative.utilities import converter\n",
        "from ai_edge_torch.generative.utilities.export_config import ExportConfig\n",
        "\n",
        "\n",
        "PREFILL_SEQ_LENS = [512]\n",
        "KV_CACHE_MAX_LEN = 1024\n",
        "\n",
        "def _create_mask(mask_len, kv_cache_max_len):\n",
        "  mask = torch.full(\n",
        "      (mask_len, kv_cache_max_len), float('-inf'), dtype=torch.float32\n",
        "  )\n",
        "  mask = torch.triu(mask, diagonal=1).unsqueeze(0).unsqueeze(0)\n",
        "  return mask\n",
        "\n",
        "\n",
        "def _create_export_config(\n",
        "    prefill_seq_lens: list[int], kv_cache_max_len: int\n",
        ") -> ExportConfig:\n",
        "  \"\"\"Creates the export config for the model.\"\"\"\n",
        "  export_config = ExportConfig()\n",
        "  if isinstance(prefill_seq_lens, list):\n",
        "    prefill_mask = [_create_mask(i, kv_cache_max_len) for i in prefill_seq_lens]\n",
        "  else:\n",
        "    prefill_mask = _create_mask(prefill_seq_lens, kv_cache_max_len)\n",
        "\n",
        "  export_config.prefill_mask = prefill_mask\n",
        "\n",
        "  decode_mask = torch.full(\n",
        "      (1, kv_cache_max_len), float('-inf'), dtype=torch.float32\n",
        "  )\n",
        "  decode_mask = torch.triu(decode_mask, diagonal=1).unsqueeze(0).unsqueeze(0)\n",
        "  export_config.decode_mask = decode_mask\n",
        "  export_config.kvcache_layout = kv_cache.KV_LAYOUT_TRANSPOSED\n",
        "  export_config.mask_as_input = True\n",
        "  return export_config\n",
        "\n",
        "\n",
        "def convert_to_litert():\n",
        "  with torch.inference_mode(True):\n",
        "    pytorch_model = gemma3.build_model_1b(\n",
        "      \"/content/merged_model\", kv_cache_max_len=KV_CACHE_MAX_LEN,\n",
        "    )\n",
        "    converter.convert_to_tflite(\n",
        "        pytorch_model,\n",
        "        output_path=\"/content/\",\n",
        "        output_name_prefix=\"gemma3_1b_finetune\",\n",
        "        prefill_seq_len=PREFILL_SEQ_LENS,\n",
        "        quantize=converter.QuantizationName.DYNAMIC_INT8,\n",
        "        lora_ranks=None,\n",
        "        export_config=_create_export_config(\n",
        "            prefill_seq_lens=PREFILL_SEQ_LENS,\n",
        "            kv_cache_max_len=KV_CACHE_MAX_LEN,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Run model conversion.\n",
        "convert_to_litert()"
      ],
      "metadata": {
        "id": "3HZIygmEJFgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ai_edge_litert import interpreter as interpreter_lib\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from collections.abc import Sequence\n",
        "import sys"
      ],
      "metadata": {
        "id": "XPK7L844pLSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = 'google/gemma-3-1b-pt'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.chat_template = \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\""
      ],
      "metadata": {
        "id": "kP20SFJopNUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = interpreter_lib.InterpreterWithCustomOps(\n",
        "    custom_op_registerers=[\"pywrap_genai_ops.GenAIOpsRegisterer\"],\n",
        "    model_path=\"/content/gemma3_1b_finetune_q8_ekv1024.tflite\", # supported on both CPU and GPU on Android\n",
        "    num_threads=2,\n",
        "    experimental_default_delegate_latest_features=True)"
      ],
      "metadata": {
        "id": "vRga1sTDpPZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create pipeline with LiteRT models"
      ],
      "metadata": {
        "id": "_s4msOvTJ77I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_mask(shape: Sequence[int], k: int):\n",
        "  \"\"\"Gets the mask for the input to the model.\n",
        "\n",
        "  Args:\n",
        "    shape: The shape of the mask input to the model.\n",
        "    k: all elements below the k-th diagonal are set to 0.\n",
        "\n",
        "  Returns:\n",
        "    The mask for the input to the model. All the elements in the mask are set\n",
        "    to -inf except that all the elements below the k-th diagonal are set to 0.\n",
        "  \"\"\"\n",
        "  mask = np.ones(shape, dtype=np.float32) * float(\"-inf\")\n",
        "  mask = np.triu(mask, k=k)\n",
        "  return mask\n",
        "\n",
        "class LiteRTLlmPipeline:\n",
        "\n",
        "  def __init__(self, interpreter, tokenizer):\n",
        "    \"\"\"Initializes the pipeline.\"\"\"\n",
        "    self._interpreter = interpreter\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "    self._prefill_runner = None\n",
        "    self._decode_runner = self._interpreter.get_signature_runner(\"decode\")\n",
        "\n",
        "\n",
        "  def _init_prefill_runner(self, num_input_tokens: int):\n",
        "    \"\"\"Initializes all the variables related to the prefill runner.\n",
        "\n",
        "    This method initializes the following variables:\n",
        "      - self._prefill_runner: The prefill runner based on the input size.\n",
        "      - self._max_seq_len: The maximum sequence length supported by the model.\n",
        "\n",
        "    Args:\n",
        "      num_input_tokens: The number of input tokens.\n",
        "    \"\"\"\n",
        "    if not self._interpreter:\n",
        "      raise ValueError(\"Interpreter is not initialized.\")\n",
        "\n",
        "    # Prefill runner related variables will be initialized in `predict_text` and\n",
        "    # `compute_log_likelihood`.\n",
        "    self._prefill_runner = self._get_prefill_runner(num_input_tokens)\n",
        "    # input_token_shape has shape (batch, max_seq_len)\n",
        "    input_token_shape = self._prefill_runner.get_input_details()[\"tokens\"][\n",
        "        \"shape\"\n",
        "    ]\n",
        "    if len(input_token_shape) == 1:\n",
        "      self._max_seq_len = input_token_shape[0]\n",
        "    else:\n",
        "      self._max_seq_len = input_token_shape[1]\n",
        "\n",
        "    # kv cache input has shape [batch=1, num_kv_heads, cache_size, head_dim].\n",
        "    kv_cache_shape = self._prefill_runner.get_input_details()[\"kv_cache_k_0\"][\n",
        "        \"shape\"\n",
        "    ]\n",
        "    self._max_kv_cache_seq_len = kv_cache_shape[2]\n",
        "\n",
        "  def _init_kv_cache(self) -> dict[str, np.ndarray]:\n",
        "    if self._prefill_runner is None:\n",
        "      raise ValueError(\"Prefill runner is not initialized.\")\n",
        "    kv_cache = {}\n",
        "    for input_key in self._prefill_runner.get_input_details().keys():\n",
        "      if \"kv_cache\" in input_key:\n",
        "        kv_cache[input_key] = np.zeros(\n",
        "            self._prefill_runner.get_input_details()[input_key][\"shape\"],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        kv_cache[input_key] = np.zeros(\n",
        "            self._prefill_runner.get_input_details()[input_key][\"shape\"],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "    return kv_cache\n",
        "\n",
        "  def _get_prefill_runner(self, num_input_tokens: int) :\n",
        "    \"\"\"Gets the prefill runner with the best suitable input size.\n",
        "\n",
        "    Args:\n",
        "      num_input_tokens: The number of input tokens.\n",
        "\n",
        "    Returns:\n",
        "      The prefill runner with the smallest input size.\n",
        "    \"\"\"\n",
        "    best_signature = None\n",
        "    delta = sys.maxsize\n",
        "    max_prefill_len = -1\n",
        "    for key in self._interpreter.get_signature_list().keys():\n",
        "      if \"prefill\" not in key:\n",
        "        continue\n",
        "      input_pos = self._interpreter.get_signature_runner(key).get_input_details()[\n",
        "          \"input_pos\"\n",
        "      ]\n",
        "      # input_pos[\"shape\"] has shape (max_seq_len, )\n",
        "      seq_size = input_pos[\"shape\"][0]\n",
        "      max_prefill_len = max(max_prefill_len, seq_size)\n",
        "      if num_input_tokens <= seq_size and seq_size - num_input_tokens < delta:\n",
        "        delta = seq_size - num_input_tokens\n",
        "        best_signature = key\n",
        "    if best_signature is None:\n",
        "      raise ValueError(\n",
        "          \"The largest prefill length supported is %d, but we have %d number of input tokens\"\n",
        "          %(max_prefill_len, num_input_tokens)\n",
        "      )\n",
        "    return self._interpreter.get_signature_runner(best_signature)\n",
        "\n",
        "  def _run_prefill(\n",
        "      self, prefill_token_ids: Sequence[int],\n",
        "  ) -> dict[str, np.ndarray]:\n",
        "    \"\"\"Runs prefill and returns the kv cache.\n",
        "\n",
        "    Args:\n",
        "      prefill_token_ids: The token ids of the prefill input.\n",
        "\n",
        "    Returns:\n",
        "      The updated kv cache.\n",
        "    \"\"\"\n",
        "    if not self._prefill_runner:\n",
        "      raise ValueError(\"Prefill runner is not initialized.\")\n",
        "    prefill_token_length = len(prefill_token_ids)\n",
        "    if prefill_token_length == 0:\n",
        "      return self._init_kv_cache()\n",
        "\n",
        "    # Prepare the input to be [1, max_seq_len].\n",
        "    input_token_ids = [0] * self._max_seq_len\n",
        "    input_token_ids[:prefill_token_length] = prefill_token_ids\n",
        "    input_token_ids = np.asarray(input_token_ids, dtype=np.int32)\n",
        "    input_token_ids = np.expand_dims(input_token_ids, axis=0)\n",
        "\n",
        "    # Prepare the input position to be [max_seq_len].\n",
        "    input_pos = [0] * self._max_seq_len\n",
        "    input_pos[:prefill_token_length] = range(prefill_token_length)\n",
        "    input_pos = np.asarray(input_pos, dtype=np.int32)\n",
        "\n",
        "    # Initialize kv cache.\n",
        "    prefill_inputs = self._init_kv_cache()\n",
        "    # Prepare the tokens and input position inputs.\n",
        "    prefill_inputs.update({\n",
        "        \"tokens\": input_token_ids,\n",
        "        \"input_pos\": input_pos,\n",
        "    })\n",
        "    if \"mask\" in self._prefill_runner.get_input_details().keys():\n",
        "      # For prefill, mask has shape [batch=1, 1, seq_len, kv_cache_size].\n",
        "      # We want mask[0, 0, i, j] = 0 for j<=i and -inf otherwise.\n",
        "      prefill_inputs[\"mask\"] = _get_mask(\n",
        "          shape=self._prefill_runner.get_input_details()[\"mask\"][\"shape\"],\n",
        "          k=1,\n",
        "      )\n",
        "    prefill_outputs = self._prefill_runner(**prefill_inputs)\n",
        "    if \"logits\" in prefill_outputs:\n",
        "      # Prefill outputs includes logits and kv cache. We only output kv cache.\n",
        "      prefill_outputs.pop(\"logits\")\n",
        "\n",
        "    return prefill_outputs\n",
        "\n",
        "  def _greedy_sampler(self, logits: np.ndarray) -> int:\n",
        "    return int(np.argmax(logits))\n",
        "\n",
        "\n",
        "  def _run_decode(\n",
        "      self,\n",
        "      start_pos: int,\n",
        "      start_token_id: int,\n",
        "      kv_cache: dict[str, np.ndarray],\n",
        "      max_decode_steps: int,\n",
        "  ) -> str:\n",
        "    \"\"\"Runs decode and outputs the token ids from greedy sampler.\n",
        "\n",
        "    Args:\n",
        "      start_pos: The position of the first token of the decode input.\n",
        "      start_token_id: The token id of the first token of the decode input.\n",
        "      kv_cache: The kv cache from the prefill.\n",
        "      max_decode_steps: The max decode steps.\n",
        "\n",
        "    Returns:\n",
        "      The token ids from the greedy sampler.\n",
        "    \"\"\"\n",
        "    next_pos = start_pos\n",
        "    next_token = start_token_id\n",
        "    decode_text = []\n",
        "    decode_inputs = kv_cache\n",
        "\n",
        "    for _ in range(max_decode_steps):\n",
        "      decode_inputs.update({\n",
        "          \"tokens\": np.array([[next_token]], dtype=np.int32),\n",
        "          \"input_pos\": np.array([next_pos], dtype=np.int32),\n",
        "      })\n",
        "      if \"mask\" in self._decode_runner.get_input_details().keys():\n",
        "        # For decode, mask has shape [batch=1, 1, 1, kv_cache_size].\n",
        "        # We want mask[0, 0, 0, j] = 0 for j<=next_pos and -inf otherwise.\n",
        "        decode_inputs[\"mask\"] = _get_mask(\n",
        "            shape=self._decode_runner.get_input_details()[\"mask\"][\"shape\"],\n",
        "            k=next_pos + 1,\n",
        "        )\n",
        "      decode_outputs = self._decode_runner(**decode_inputs)\n",
        "      # Output logits has shape (batch=1, 1, vocab_size). We only take the first\n",
        "      # element.\n",
        "      logits = decode_outputs.pop(\"logits\")[0][0]\n",
        "      next_token = self._greedy_sampler(logits)\n",
        "      if next_token == self._tokenizer.eos_token_id:\n",
        "        break\n",
        "      decode_text.append(self._tokenizer.decode(next_token, skip_special_tokens=True))\n",
        "      if len(decode_text[-1]) == 0:\n",
        "        # Break out the loop if we hit the special token.\n",
        "        break\n",
        "\n",
        "      print(decode_text[-1], end='', flush=True)\n",
        "      # Decode outputs includes logits and kv cache. We already poped out\n",
        "      # logits, so the rest is kv cache. We pass the updated kv cache as input\n",
        "      # to the next decode step.\n",
        "      decode_inputs = decode_outputs\n",
        "      next_pos += 1\n",
        "\n",
        "    print() # print a new line at the end.\n",
        "    return ''.join(decode_text)\n",
        "\n",
        "  def generate(self, prompt: str, max_decode_steps: int | None = None) -> str:\n",
        "    messages=[{ 'role': 'user', 'content': prompt}]\n",
        "    token_ids = self._tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)\n",
        "    # Initialize the prefill runner with the suitable input size.\n",
        "    self._init_prefill_runner(len(token_ids))\n",
        "\n",
        "    # Run prefill.\n",
        "    # Prefill up to the seond to the last token of the prompt, because the last\n",
        "    # token of the prompt will be used to bootstrap decode.\n",
        "    prefill_token_length = len(token_ids) - 1\n",
        "\n",
        "    print('Running prefill')\n",
        "    kv_cache = self._run_prefill(token_ids[:prefill_token_length])\n",
        "    # Run decode.\n",
        "    print('Running decode')\n",
        "    actual_max_decode_steps = self._max_kv_cache_seq_len - prefill_token_length - 1\n",
        "    if max_decode_steps is not None:\n",
        "      actual_max_decode_steps = min(actual_max_decode_steps, max_decode_steps)\n",
        "    decode_text = self._run_decode(\n",
        "        prefill_token_length,\n",
        "        token_ids[prefill_token_length],\n",
        "        kv_cache,\n",
        "        actual_max_decode_steps,\n",
        "    )\n",
        "    return decode_text"
      ],
      "metadata": {
        "id": "2KPoRCaZpQxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate text from the converted model"
      ],
      "metadata": {
        "id": "FQ1ZVCiAJ_iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disclaimer: Model performance demonstrated with the Python API in this notebook is not representative of performance on a local device.\n",
        "pipeline = LiteRTLlmPipeline(interpreter, tokenizer)"
      ],
      "metadata": {
        "id": "U33LaaCKpUFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipeline.generate(\"\"\"Given the <USER_QUERY> and the <SCHEMA>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
        "\n",
        "<SCHEMA>\n",
        "CREATE TABLE materials (material_id INT, name VARCHAR(50), is_organic BOOLEAN); INSERT INTO materials (material_id, name, is_organic) VALUES (1, 'Organic Cotton', true), (2, 'Conventional Cotton', false), (3, 'Organic Hemp', true); CREATE TABLE products_materials (product_id INT, material_id INT); INSERT INTO products_materials (product_id, material_id) VALUES (1, 1), (2, 2), (3, 3), (4, 1);\n",
        "</SCHEMA>\n",
        "\n",
        "<USER_QUERY>\n",
        "What is the total number of products made from organic materials?\n",
        "</USER_QUERY>\"\"\", max_decode_steps = 256)"
      ],
      "metadata": {
        "id": "LuI6OGsTpUpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare task bundle for MediaPipe deployment\n",
        "The task file will be named as `gemma3_1b_it_q8_ekv1024.task`, and placed under the `/content` directory. Please refer to https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference about how to deploy the task file with MediaPipe LLM inference example."
      ],
      "metadata": {
        "id": "HGlWvqdFKZoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import joblib\n",
        "\n",
        "REPO_ID = \"google/gemma-3-1b-it\"\n",
        "FILENAME = \"tokenizer.model\"\n",
        "\n",
        "tokenizer_model = (\n",
        "    hf_hub_download(repo_id=REPO_ID, filename=FILENAME, local_dir=\"/content\", token=hf_token)\n",
        ")"
      ],
      "metadata": {
        "id": "EwWofyxkpWGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe.tasks.python.genai.bundler import llm_bundler\n",
        "\n",
        "def build_task_bundle():\n",
        "  output_file = \"/content/gemma3_1b_finetune_q8_ekv1024.task\"\n",
        "  tflite_model = \"/content/gemma3_1b_finetune_q8_ekv1024.tflite\"\n",
        "  tokenizer_model = (\n",
        "      \"/content/tokenizer.model\"\n",
        "  )\n",
        "  config = llm_bundler.BundleConfig(\n",
        "      tflite_model=tflite_model,\n",
        "      tokenizer_model=tokenizer_model,\n",
        "      start_token=\"<bos>\",\n",
        "      stop_tokens=[\"<eos>\", \"<end_of_turn>\"],\n",
        "      output_filename=output_file,\n",
        "      enable_bytes_to_unicode_mapping=False,\n",
        "      prompt_prefix=\"<start_of_turn>user\\n\",\n",
        "      prompt_suffix=\"<end_of_turn>\\n<start_of_turn>model\\n\",\n",
        "  )\n",
        "  llm_bundler.create_bundle(config)\n",
        "\n",
        "# Build the MediaPipe task bundle.\n",
        "build_task_bundle()"
      ],
      "metadata": {
        "id": "Dtj9nytmpX8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try it out with AI Edge Gallery\n",
        "\n",
        "* Download and install the [apk](https://github.com/google-ai-edge/gallery/releases/latest/download/ai-edge-gallery.apk).\n",
        "* Follow the instructions in the app. If you upload the MediaPipe task bundle in the following step then it's easy to load that into Gallery to test out."
      ],
      "metadata": {
        "id": "XWnUYbs3sF1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy MediaPipe task bundle to Google Drive.\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "shutil.copy(\"gemma3_1b_finetune_q8_ekv1024.task\", \"/content/drive/MyDrive/\")"
      ],
      "metadata": {
        "id": "1ZDAWOfEn5BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration with your mobile application\n",
        "Check out our MediaPipe LLM Inference API [guide](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference) on how to integrate your model into your Android, iOS, or Web application!"
      ],
      "metadata": {
        "id": "yAo7fJLv8fKL"
      }
    }
  ]
}